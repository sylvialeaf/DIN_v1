# ğŸš€ äº‘ç«¯ GPU éƒ¨ç½²æŒ‡å—

æœ¬é¡¹ç›®æ”¯æŒåœ¨å¤šç§äº‘ç«¯ GPU å¹³å°è¿è¡Œï¼Œä»¥ä¸‹æ˜¯è¯¦ç»†çš„éƒ¨ç½²æ­¥éª¤ã€‚

---

## ğŸ“‹ ç›®å½•
- [å¹³å°é€‰æ‹©](#å¹³å°é€‰æ‹©)
- [AutoDL éƒ¨ç½²ï¼ˆæ¨èï¼‰](#autodl-éƒ¨ç½²)
- [Google Colab éƒ¨ç½²](#google-colab-éƒ¨ç½²)
- [é˜¿é‡Œäº‘/è…¾è®¯äº‘éƒ¨ç½²](#é˜¿é‡Œäº‘è…¾è®¯äº‘éƒ¨ç½²)
- [è¿è¡Œå®éªŒ](#è¿è¡Œå®éªŒ)
- [é¢„ä¼°æ—¶é—´å’Œæˆæœ¬](#é¢„ä¼°æ—¶é—´å’Œæˆæœ¬)

---

## ğŸ¯ å¹³å°é€‰æ‹©

| å¹³å° | æˆæœ¬ | GPU | æ¨èåº¦ | é€‚åˆåœºæ™¯ |
|------|------|-----|--------|----------|
| **AutoDL** | Â¥1-2/å°æ—¶ | RTX 3090/A5000 | â­â­â­â­â­ | å›½å†…é¦–é€‰ |
| **Colab Pro** | $10/æœˆ | T4/V100 | â­â­â­â­ | å…è´¹è¯•ç”¨ |
| **é˜¿é‡Œäº‘ PAI-DSW** | Â¥3-5/å°æ—¶ | V100/A10 | â­â­â­ | ä¼ä¸šç”¨æˆ· |
| **è…¾è®¯äº‘ GPU** | Â¥2-4/å°æ—¶ | T4/V100 | â­â­â­ | æŒ‰éœ€ä½¿ç”¨ |

---

## ğŸ”§ AutoDL éƒ¨ç½²

### æ­¥éª¤ 1ï¼šæ³¨å†Œå’Œåˆ›å»ºå®ä¾‹

1. è®¿é—® [AutoDL](https://www.autodl.com)
2. æ³¨å†Œè´¦å·å¹¶å……å€¼ï¼ˆå»ºè®® Â¥20-50 è¶³å¤Ÿï¼‰
3. åˆ›å»ºå®ä¾‹ï¼š
   - é€‰æ‹© GPUï¼š**RTX 3090** æˆ– **A5000**ï¼ˆçº¦ Â¥1.5/å°æ—¶ï¼‰
   - é•œåƒï¼š**PyTorch 2.0.0 + Python 3.10**
   - æ•°æ®ç›˜ï¼š10GB è¶³å¤Ÿ

### æ­¥éª¤ 2ï¼šä¸Šä¼ é¡¹ç›®

**æ–¹æ³•ä¸€ï¼šé€šè¿‡ Gitï¼ˆæ¨èï¼‰**
```bash
# åœ¨ AutoDL ç»ˆç«¯æ‰§è¡Œ
cd /root/autodl-tmp
git clone https://your-git-repo-url.git
# æˆ–è€…
git clone https://github.com/yourusername/standalone_din.git
```

**æ–¹æ³•äºŒï¼šé€šè¿‡ SCP/SFTP**
```bash
# åœ¨æœ¬åœ°æ‰§è¡Œï¼ˆWindows PowerShellï¼‰
scp -r D:\aProject\Project_RecBole\RecBole1\standalone_din root@your-autodl-ip:/root/autodl-tmp/
```

**æ–¹æ³•ä¸‰ï¼šç½‘ç›˜/å‹ç¼©åŒ…**
1. å°† `standalone_din` æ–‡ä»¶å¤¹å‹ç¼©ä¸º zip
2. ä¸Šä¼ åˆ°ç½‘ç›˜è·å–ä¸‹è½½é“¾æ¥
3. åœ¨ AutoDL ç»ˆç«¯ï¼š
```bash
cd /root/autodl-tmp
wget "ç½‘ç›˜é“¾æ¥" -O project.zip
unzip project.zip
```

### æ­¥éª¤ 3ï¼šå®‰è£…ä¾èµ–

```bash
cd /root/autodl-tmp/standalone_din
pip install torch numpy pandas matplotlib scikit-learn lightgbm tqdm tensorboard
```

### æ­¥éª¤ 4ï¼šè¿è¡Œå®éªŒ

```bash
# å®Œæ•´å®éªŒï¼ˆä¸¤ä¸ªæ•°æ®é›†ï¼Œçº¦ 2 å°æ—¶ï¼‰
python run_all_gpu.py

# åªè·‘ ml-100kï¼ˆçº¦ 20 åˆ†é’Ÿï¼‰
python run_all_gpu.py --dataset ml-100k

# åªè·‘ ml-1mï¼ˆçº¦ 90 åˆ†é’Ÿï¼‰
python run_all_gpu.py --dataset ml-1m

# å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼ˆéªŒè¯ç¯å¢ƒï¼Œçº¦ 5 åˆ†é’Ÿï¼‰
python run_all_gpu.py --quick

# æŒ‡å®š epoch æ•°é‡
python run_all_gpu.py --epochs 100
```

---

## ğŸ““ Google Colab éƒ¨ç½²

### æ­¥éª¤ 1ï¼šåˆ›å»ºæ–°ç¬”è®°æœ¬

1. è®¿é—® [Google Colab](https://colab.research.google.com)
2. æ–°å»ºç¬”è®°æœ¬
3. èœå•ï¼šè¿è¡Œæ—¶ â†’ æ›´æ”¹è¿è¡Œæ—¶ç±»å‹ â†’ GPU

### æ­¥éª¤ 2ï¼šä¸Šä¼ é¡¹ç›®

```python
# Cell 1: æŒ‚è½½ Google Driveï¼ˆå¯é€‰ï¼‰
from google.colab import drive
drive.mount('/content/drive')

# Cell 2: ä¸Šä¼ å‹ç¼©åŒ…
from google.colab import files
uploaded = files.upload()  # é€‰æ‹© standalone_din.zip

# Cell 3: è§£å‹
!unzip standalone_din.zip -d /content/
```

### æ­¥éª¤ 3ï¼šå®‰è£…ä¾èµ–

```python
# Cell 4
!pip install lightgbm
```

### æ­¥éª¤ 4ï¼šè¿è¡Œå®éªŒ

```python
# Cell 5
%cd /content/standalone_din
!python run_all_gpu.py --quick  # å…ˆå¿«é€Ÿæµ‹è¯•

# Cell 6: å®Œæ•´å®éªŒ
!python run_all_gpu.py
```

### æ­¥éª¤ 5ï¼šä¸‹è½½ç»“æœ

```python
# Cell 7
from google.colab import files
import zipfile
import os

# å‹ç¼©ç»“æœ
with zipfile.ZipFile('results.zip', 'w') as z:
    for f in os.listdir('results_gpu'):
        z.write(os.path.join('results_gpu', f))

files.download('results.zip')
```

---

## â˜ï¸ é˜¿é‡Œäº‘/è…¾è®¯äº‘éƒ¨ç½²

### é˜¿é‡Œäº‘ PAI-DSW

1. ç™»å½•é˜¿é‡Œäº‘æ§åˆ¶å° â†’ äººå·¥æ™ºèƒ½å¹³å° PAI
2. åˆ›å»º DSW å®ä¾‹ï¼š
   - GPU ç±»å‹ï¼šV100 æˆ– A10
   - é•œåƒï¼šPyTorch 2.0
3. æ‰“å¼€ Terminalï¼ŒæŒ‰ AutoDL æ­¥éª¤æ“ä½œ

### è…¾è®¯äº‘ GPU äº‘æœåŠ¡å™¨

1. è´­ä¹° GPU å®ä¾‹ï¼ˆæŒ‰é‡è®¡è´¹ï¼‰
2. é€‰æ‹©å¸¦ CUDA çš„é•œåƒ
3. SSH è¿æ¥åæŒ‰ AutoDL æ­¥éª¤æ“ä½œ

---

## âš¡ è¿è¡Œå®éªŒ

### å‘½ä»¤å‚æ•°è¯´æ˜

```bash
python run_all_gpu.py [å‚æ•°]

å‚æ•°:
  --dataset {ml-100k,ml-1m,both}  # é€‰æ‹©æ•°æ®é›†ï¼Œé»˜è®¤ both
  --quick                          # å¿«é€Ÿæµ‹è¯•æ¨¡å¼
  --epochs N                       # è®­ç»ƒè½®æ•°ï¼Œé»˜è®¤ 50
```

### æ¨èè¿è¡Œé¡ºåº

```bash
# 1. éªŒè¯ç¯å¢ƒ
python run_all_gpu.py --quick

# 2. æµ‹è¯•å°æ•°æ®é›†
python run_all_gpu.py --dataset ml-100k --epochs 30

# 3. å®Œæ•´å®éªŒ
python run_all_gpu.py --epochs 50
```

---

## â±ï¸ é¢„ä¼°æ—¶é—´å’Œæˆæœ¬

### GPU è¿è¡Œæ—¶é—´

| é…ç½® | ml-100k | ml-1m | æ€»è®¡ |
|------|---------|-------|------|
| epochs=20, quick | 5 åˆ†é’Ÿ | 15 åˆ†é’Ÿ | 20 åˆ†é’Ÿ |
| epochs=50 | 15 åˆ†é’Ÿ | 60 åˆ†é’Ÿ | 1.5 å°æ—¶ |
| epochs=100 | 30 åˆ†é’Ÿ | 120 åˆ†é’Ÿ | 2.5 å°æ—¶ |

### æˆæœ¬ä¼°ç®—ï¼ˆAutoDL RTX 3090ï¼‰

| é…ç½® | æ—¶é—´ | æˆæœ¬ |
|------|------|------|
| Quick æ¨¡å¼ | 20 åˆ†é’Ÿ | Â¥0.5 |
| æ ‡å‡†æ¨¡å¼ | 2 å°æ—¶ | Â¥3 |
| å®Œæ•´æ¨¡å¼ | 3 å°æ—¶ | Â¥4.5 |

---

## ğŸ“ è¾“å‡ºæ–‡ä»¶

å®éªŒå®Œæˆåï¼Œç»“æœä¿å­˜åœ¨ `results_gpu/` ç›®å½•ï¼š

```
results_gpu/
â”œâ”€â”€ all_results_20241221_123456.csv     # æ‰€æœ‰ç»“æœè¡¨æ ¼
â”œâ”€â”€ report_20241221_123456.json         # è¯¦ç»† JSON æŠ¥å‘Š
â””â”€â”€ ...
```

### ç»“æœå­—æ®µè¯´æ˜

| å­—æ®µ | è¯´æ˜ |
|------|------|
| experiment | å®éªŒç¼–å· (exp1/exp2) |
| dataset | æ•°æ®é›† (ml-100k/ml-1m) |
| model | æ¨¡å‹åç§° |
| test_auc | æµ‹è¯•é›† AUC |
| train_time_sec | è®­ç»ƒæ—¶é—´ï¼ˆç§’ï¼‰ |
| qps | æ¨ç†é€Ÿåº¦ï¼ˆæ ·æœ¬/ç§’ï¼‰ |

---

## ğŸ” å¸¸è§é—®é¢˜

### Q: CUDA out of memory
```bash
# å‡å° batch size
python run_all_gpu.py --quick  # ä½¿ç”¨ quick æ¨¡å¼
```

### Q: æ•°æ®ä¸‹è½½å¤±è´¥
```bash
# æ‰‹åŠ¨ä¸‹è½½æ•°æ®é›†
cd data
mkdir -p ml-100k ml-1m
# ä» https://grouplens.org/datasets/movielens/ ä¸‹è½½
```

### Q: æ‰¾ä¸åˆ°æ¨¡å—
```bash
# ç¡®ä¿åœ¨æ­£ç¡®ç›®å½•
cd /path/to/standalone_din
python -c "from models import DINRichLite; print('OK')"
```

---

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
1. GPU æ˜¯å¦æ­£ç¡®è¯†åˆ«ï¼š`python -c "import torch; print(torch.cuda.is_available())"`
2. ä¾èµ–æ˜¯å¦å®‰è£…å®Œæ•´ï¼š`pip list | grep -E "torch|numpy|pandas|lightgbm"`
3. æ–‡ä»¶ç»“æ„æ˜¯å¦æ­£ç¡®ï¼š`ls -la` ç¡®è®¤æ–‡ä»¶å­˜åœ¨
