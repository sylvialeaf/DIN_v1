#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å¢žå¼ºç‰ˆè®­ç»ƒå™¨

æ”¯æŒä¸°å¯Œç‰¹å¾çš„æ¨¡åž‹è®­ç»ƒã€‚
æ”¯æŒ CTR æŒ‡æ ‡ï¼ˆAUC, LogLossï¼‰å’Œ Top-K æŽ¨èæŒ‡æ ‡ï¼ˆRecall@K, NDCG@K, HR@K, MRRï¼‰ã€‚
"""

import torch
import torch.nn as nn
from torch.optim import Adam
from sklearn.metrics import roc_auc_score, log_loss
import numpy as np
from tqdm import tqdm
import time


# ========================================
# Top-K è¯„ä¼°æŒ‡æ ‡
# ========================================

def hit_at_k(ranked_items, ground_truth, k):
    """
    Hit Rate @ K
    å¦‚æžœ ground_truth åœ¨ top-k ä¸­ï¼Œè¿”å›ž 1ï¼Œå¦åˆ™è¿”å›ž 0
    """
    return 1.0 if ground_truth in ranked_items[:k] else 0.0


def recall_at_k(ranked_items, ground_truth, k):
    """
    Recall @ K
    å¯¹äºŽå•ä¸ª ground truthï¼Œç­‰åŒäºŽ Hit Rate
    """
    return hit_at_k(ranked_items, ground_truth, k)


def ndcg_at_k(ranked_items, ground_truth, k):
    """
    NDCG @ K (Normalized Discounted Cumulative Gain)
    """
    for i, item in enumerate(ranked_items[:k]):
        if item == ground_truth:
            # DCG = 1 / log2(rank + 1)ï¼ŒIDCG = 1 / log2(2) = 1
            return 1.0 / np.log2(i + 2)  # +2 å› ä¸º rank ä»Ž 1 å¼€å§‹
    return 0.0


def mrr_at_k(ranked_items, ground_truth, k):
    """
    MRR @ K (Mean Reciprocal Rank)
    """
    for i, item in enumerate(ranked_items[:k]):
        if item == ground_truth:
            return 1.0 / (i + 1)
    return 0.0


def precision_at_k(ranked_items, ground_truth, k):
    """
    Precision @ K
    å¯¹äºŽå•ä¸ª ground truth: å‘½ä¸­åˆ™ä¸º 1/kï¼Œå¦åˆ™ä¸º 0
    """
    if ground_truth in ranked_items[:k]:
        return 1.0 / k
    return 0.0


class RichTrainer:
    """
    å¢žå¼ºç‰ˆè®­ç»ƒå™¨
    
    æ”¯æŒ batch å­—å…¸å½¢å¼çš„è¾“å…¥ã€‚
    æ”¯æŒå¤š GPU DataParallel åŠ é€Ÿã€‚
    """
    
    def __init__(
        self,
        model,
        device='cpu',
        learning_rate=1e-3,
        weight_decay=1e-5,
        use_multi_gpu=False  # æ˜¯å¦ä½¿ç”¨å¤š GPU
    ):
        self.device = device
        self.use_multi_gpu = use_multi_gpu and torch.cuda.device_count() > 1
        
        # å°†æ¨¡åž‹ç§»åˆ°è®¾å¤‡
        model = model.to(device)
        
        # å¤š GPU æ”¯æŒ
        if self.use_multi_gpu:
            print(f"ðŸ”¥ ä½¿ç”¨ DataParallel: {torch.cuda.device_count()} GPUs")
            model = nn.DataParallel(model)
        
        self.model = model
        
        self.criterion = nn.BCEWithLogitsLoss()
        self.optimizer = Adam(
            model.parameters(), 
            lr=learning_rate,
            weight_decay=weight_decay
        )
    
    @property
    def raw_model(self):
        """èŽ·å–åŽŸå§‹æ¨¡åž‹ï¼ˆç”¨äºŽè®¿é—®æ¨¡åž‹å±žæ€§æˆ–ä¿å­˜ï¼‰"""
        if self.use_multi_gpu and hasattr(self.model, 'module'):
            return self.model.module
        return self.model
    
    def _move_batch_to_device(self, batch):
        """å°† batch ç§»åŠ¨åˆ°è®¾å¤‡"""
        return {k: v.to(self.device) for k, v in batch.items()}
    
    def train_epoch(self, train_loader, show_progress=True):
        """è®­ç»ƒä¸€ä¸ª epoch"""
        self.model.train()
        total_loss = 0
        
        iterator = tqdm(train_loader, desc='Training') if show_progress else train_loader
        
        for batch in iterator:
            batch = self._move_batch_to_device(batch)
            
            self.optimizer.zero_grad()
            
            logits = self.model(batch)
            loss = self.criterion(logits, batch['label'])
            
            loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=5.0)
            self.optimizer.step()
            
            total_loss += loss.item()
        
        return total_loss / len(train_loader)
    
    def evaluate(self, data_loader, show_progress=False):
        """è¯„ä¼°æ¨¡åž‹"""
        self.model.eval()
        
        all_preds = []
        all_labels = []
        
        iterator = tqdm(data_loader, desc='Evaluating') if show_progress else data_loader
        
        with torch.no_grad():
            for batch in iterator:
                batch = self._move_batch_to_device(batch)
                
                logits = self.model(batch)
                preds = torch.sigmoid(logits).cpu().numpy()
                labels = batch['label'].cpu().numpy()
                
                all_preds.extend(preds)
                all_labels.extend(labels)
        
        all_preds = np.array(all_preds)
        all_labels = np.array(all_labels)
        
        auc = roc_auc_score(all_labels, all_preds)
        logloss = log_loss(all_labels, np.clip(all_preds, 1e-7, 1-1e-7))
        
        return {
            'auc': auc,
            'logloss': logloss
        }
    
    def fit(
        self,
        train_loader,
        valid_loader,
        epochs=20,
        early_stopping_patience=5,
        show_progress=True
    ):
        """è®­ç»ƒæ¨¡åž‹"""
        best_valid_auc = 0
        patience_counter = 0
        best_model_state = None
        
        for epoch in range(epochs):
            train_loss = self.train_epoch(train_loader, show_progress)
            valid_metrics = self.evaluate(valid_loader)
            
            print(f"Epoch {epoch+1}/{epochs} - "
                  f"Loss: {train_loss:.4f} - "
                  f"Valid AUC: {valid_metrics['auc']:.4f} - "
                  f"Valid LogLoss: {valid_metrics['logloss']:.4f}")
            
            if valid_metrics['auc'] > best_valid_auc:
                best_valid_auc = valid_metrics['auc']
                best_model_state = self.model.state_dict().copy()
                patience_counter = 0
            else:
                patience_counter += 1
                if patience_counter >= early_stopping_patience:
                    print(f"Early stopping at epoch {epoch+1}")
                    break
        
        if best_model_state is not None:
            self.model.load_state_dict(best_model_state)
        
        return {
            'best_valid_auc': best_valid_auc,
            'final_epoch': epoch + 1
        }
    
    def evaluate_topk(
        self,
        eval_data,
        feature_processor,
        interaction_extractor,
        max_seq_length,
        ks=[5, 10, 20],
        show_progress=True,
        batch_size=256
    ):
        """
        Top-K æŽ¨èè¯„ä¼°ï¼ˆæ‰¹é‡ä¼˜åŒ–ç‰ˆï¼‰
        
        Args:
            eval_data: list of dictï¼Œæ¥è‡ª get_topk_eval_data
            feature_processor: ç‰¹å¾å¤„ç†å™¨
            interaction_extractor: äº¤äº’ç‰¹å¾æå–å™¨
            max_seq_length: æœ€å¤§åºåˆ—é•¿åº¦
            ks: è¯„ä¼°çš„ K å€¼åˆ—è¡¨
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
            batch_size: æ‰¹é‡è¯„ä¼°çš„ç”¨æˆ·æ•°
        
        Returns:
            dict: å„æŒ‡æ ‡åœ¨ä¸åŒ K ä¸‹çš„å€¼
        """
        from data_loader import build_topk_batch_multi
        
        self.model.eval()
        
        # åˆå§‹åŒ–æŒ‡æ ‡ç´¯åŠ å™¨
        all_hr = {k: [] for k in ks}
        all_ndcg = {k: [] for k in ks}
        all_mrr = {k: [] for k in ks}
        
        # åˆ†æ‰¹å¤„ç†
        num_users = len(eval_data)
        num_batches = (num_users + batch_size - 1) // batch_size
        
        iterator = range(num_batches)
        if show_progress:
            iterator = tqdm(iterator, desc='Top-K Eval')
        
        with torch.no_grad():
            for batch_idx in iterator:
                start_idx = batch_idx * batch_size
                end_idx = min(start_idx + batch_size, num_users)
                batch_eval_data = eval_data[start_idx:end_idx]
                
                # æ‰¹é‡æž„å»ºå¹¶è¯„ä¼°
                for eval_item in batch_eval_data:
                    # æž„å»ºå•ç”¨æˆ·çš„å€™é€‰ batch
                    batch = build_topk_batch_multi(
                        eval_item, feature_processor, interaction_extractor,
                        max_seq_length, self.device
                    )
                    
                    # é¢„æµ‹åˆ†æ•°
                    logits = self.model(batch)
                    scores = torch.sigmoid(logits).cpu().numpy()
                    
                    # æŽ’åº
                    candidates = eval_item['candidates']
                    ground_truth = eval_item['ground_truth']
                    sorted_indices = np.argsort(-scores)
                    ranked_items = [candidates[i] for i in sorted_indices]
                    
                    # è®¡ç®—æŒ‡æ ‡
                    for k in ks:
                        all_hr[k].append(hit_at_k(ranked_items, ground_truth, k))
                        all_ndcg[k].append(ndcg_at_k(ranked_items, ground_truth, k))
                        all_mrr[k].append(mrr_at_k(ranked_items, ground_truth, k))
        
        # è®¡ç®—å¹³å‡å€¼
        results = {}
        for k in ks:
            results[f'HR@{k}'] = np.mean(all_hr[k])
            results[f'Recall@{k}'] = np.mean(all_hr[k])  # å• GT ç­‰äºŽ HR
            results[f'NDCG@{k}'] = np.mean(all_ndcg[k])
            results[f'MRR@{k}'] = np.mean(all_mrr[k])
            results[f'Precision@{k}'] = np.mean(all_hr[k]) / k
        
        return results


def measure_inference_speed_rich(model, data_loader, device='cpu', warmup_batches=5, measure_batches=20):
    """
    æµ‹é‡æŽ¨ç†é€Ÿåº¦ï¼ˆQPSï¼‰
    
    é€‚ç”¨äºŽ batch å­—å…¸è¾“å…¥çš„æ¨¡åž‹ã€‚
    """
    model.eval()
    model = model.to(device)
    
    sample_batch = next(iter(data_loader))
    batch_size = sample_batch['user_id'].shape[0]
    
    # Warmup
    with torch.no_grad():
        for i, batch in enumerate(data_loader):
            if i >= warmup_batches:
                break
            batch = {k: v.to(device) for k, v in batch.items()}
            _ = model(batch)
    
    # æµ‹é‡
    total_samples = 0
    start_time = time.time()
    
    with torch.no_grad():
        for i, batch in enumerate(data_loader):
            if i >= measure_batches:
                break
            batch = {k: v.to(device) for k, v in batch.items()}
            _ = model(batch)
            total_samples += batch['user_id'].shape[0]
    
    elapsed = time.time() - start_time
    qps = total_samples / elapsed if elapsed > 0 else 0
    
    return {
        'qps': qps,
        'total_samples': total_samples,
        'elapsed_time': elapsed
    }


if __name__ == "__main__":
    print("æµ‹è¯•å¢žå¼ºç‰ˆè®­ç»ƒå™¨...")
    
    from data_loader import get_rich_dataloaders
    from models import DINRichLite
    
    train_loader, valid_loader, test_loader, info, fp = get_rich_dataloaders(
        data_dir='./data',
        dataset_name='ml-100k',
        max_seq_length=50,
        batch_size=256
    )
    
    model = DINRichLite(
        num_items=info['num_items'],
        num_users=info['num_users'],
        feature_dims=info['feature_dims'],
        embedding_dim=64
    )
    
    trainer = RichTrainer(model=model, device='cpu')
    
    # å¿«é€Ÿæµ‹è¯•
    result = trainer.fit(
        train_loader=train_loader,
        valid_loader=valid_loader,
        epochs=2,
        show_progress=True
    )
    
    print(f"\nè®­ç»ƒç»“æžœ: {result}")
    
    test_metrics = trainer.evaluate(test_loader)
    print(f"æµ‹è¯•ç»“æžœ: {test_metrics}")
