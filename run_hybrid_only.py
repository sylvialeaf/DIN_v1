#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å•ç‹¬è¿è¡Œæ··åˆç²¾æ’æ¨¡å‹ (DIN + LightGBM)

åŠŸèƒ½ï¼š
1. è®­ç»ƒ DIN æ¨¡å‹ï¼ˆå¦‚æœæ²¡æœ‰é¢„è®­ç»ƒæ¨¡å‹ï¼‰
2. è®­ç»ƒæ··åˆç²¾æ’æ¨¡å‹
3. è¯„ä¼°å¹¶ä¿å­˜ç‰¹å¾é‡è¦æ€§ç­‰å¯è§£é‡Šæ€§åˆ†æç»“æœ

ç”¨æ³•ï¼š
    python run_hybrid_only.py                    # é»˜è®¤é…ç½®
    python run_hybrid_only.py --dataset ml-1m    # ä½¿ç”¨ml-1mæ•°æ®é›†
    python run_hybrid_only.py --seq_length 100   # è‡ªå®šä¹‰åºåˆ—é•¿åº¦
"""

import os
import sys
import json
import time
import argparse
from datetime import datetime

print("ğŸ”§ å¯¼å…¥ä¾èµ–åº“...")

try:
    import torch
    print("âœ… PyTorch å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ PyTorch å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

try:
    import numpy as np
    import pandas as pd
    print("âœ… NumPy, Pandas å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from data_loader import MovieLensDataLoader
    from feature_engineering import FeatureProcessor, InteractionExtractor
    from models import DIN
    from trainer import Trainer
    from hybrid_ranker import HybridRanker, EXPLICIT_FEATURE_NAMES
    print("âœ… é¡¹ç›®æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ é¡¹ç›®æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print(f"   å½“å‰ç›®å½•: {os.getcwd()}")
    print(f"   è„šæœ¬ç›®å½•: {os.path.dirname(os.path.abspath(__file__))}")
    sys.exit(1)

# ========================================
# é…ç½®
# ========================================

def parse_args():
    parser = argparse.ArgumentParser(description='å•ç‹¬è¿è¡Œæ··åˆç²¾æ’æ¨¡å‹')
    parser.add_argument('--dataset', type=str, default='ml-100k', choices=['ml-100k', 'ml-1m'],
                        help='æ•°æ®é›†åç§°')
    parser.add_argument('--seq_length', type=int, default=50, help='æœ€å¤§åºåˆ—é•¿åº¦')
    parser.add_argument('--embedding_dim', type=int, default=64, help='åµŒå…¥ç»´åº¦')
    parser.add_argument('--batch_size', type=int, default=256, help='æ‰¹å¤§å°')
    parser.add_argument('--epochs', type=int, default=30, help='DINè®­ç»ƒè½®æ•°')
    parser.add_argument('--lr', type=float, default=0.001, help='å­¦ä¹ ç‡')
    parser.add_argument('--lgb_rounds', type=int, default=300, help='LightGBMè¿­ä»£æ¬¡æ•°')
    parser.add_argument('--early_stop', type=int, default=30, help='æ—©åœè½®æ•°')
    parser.add_argument('--device', type=str, default='auto', help='è®¾å¤‡ (cuda/cpu/auto)')
    parser.add_argument('--output_dir', type=str, default='results', help='ç»“æœä¿å­˜ç›®å½•')
    return parser.parse_args()


def main():
    args = parse_args()
    
    print("ğŸš€ å¼€å§‹è¿è¡Œ...")
    print(f"ğŸ“ å‚æ•°è§£ææˆåŠŸ: dataset={args.dataset}, seq_length={args.seq_length}")
    
    # è®¾å¤‡
    if args.device == 'auto':
        DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
    else:
        DEVICE = args.device
    
    print("=" * 80)
    print("ğŸš€ æ··åˆç²¾æ’æ¨¡å‹å•ç‹¬è®­ç»ƒè„šæœ¬")
    print("=" * 80)
    print(f"\nğŸ“‹ é…ç½®:")
    print(f"   æ•°æ®é›†: {args.dataset}")
    print(f"   åºåˆ—é•¿åº¦: {args.seq_length}")
    print(f"   åµŒå…¥ç»´åº¦: {args.embedding_dim}")
    print(f"   è®¾å¤‡: {DEVICE}")
    if DEVICE == 'cuda':
        print(f"   GPU: {torch.cuda.get_device_name(0)}")
    
    start_time = datetime.now()
    
    # ========================================
    # 1. æ•°æ®åŠ è½½
    # ========================================
    print("\n" + "=" * 60)
    print("ğŸ“¦ Step 1: åŠ è½½æ•°æ®")
    print("=" * 60)
    
    data_loader = MovieLensDataLoader(
        dataset_name=args.dataset,
        max_seq_length=args.seq_length
    )
    
    train_loader, valid_loader, test_loader = data_loader.get_dataloaders(
        batch_size=args.batch_size,
        num_workers=4
    )
    
    dataset_info = data_loader.get_dataset_info()
    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ")
    print(f"   ç”¨æˆ·æ•°: {dataset_info['num_users']}")
    print(f"   ç‰©å“æ•°: {dataset_info['num_items']}")
    print(f"   ç±»å‹æ•°: {dataset_info['num_genres']}")
    print(f"   è®­ç»ƒæ ·æœ¬: {len(train_loader.dataset)}")
    
    # ========================================
    # 2. ç‰¹å¾å¤„ç†å™¨
    # ========================================
    print("\n" + "=" * 60)
    print("ğŸ”§ Step 2: åˆå§‹åŒ–ç‰¹å¾å¤„ç†å™¨")
    print("=" * 60)
    
    feature_processor = FeatureProcessor(data_loader.ratings_df, data_loader.users_df, data_loader.items_df)
    interaction_extractor = InteractionExtractor(data_loader.ratings_df)
    
    print(f"âœ… ç‰¹å¾å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    print(f"   æ˜¾å¼ç‰¹å¾æ•°: {len(EXPLICIT_FEATURE_NAMES)}")
    
    # ========================================
    # 3. è®­ç»ƒ DIN æ¨¡å‹
    # ========================================
    print("\n" + "=" * 60)
    print("ğŸ§  Step 3: è®­ç»ƒ DIN æ¨¡å‹")
    print("=" * 60)
    
    din_config = {
        'num_users': dataset_info['num_users'],
        'num_items': dataset_info['num_items'],
        'num_genres': dataset_info['num_genres'],
        'num_years': 10,
        'embedding_dim': args.embedding_dim,
        'mlp_dims': [256, 128, 64],
        'dropout': 0.2,
        'use_time_decay': True,
        'time_decay_lambda': 0.1,
    }
    
    din_model = DIN(**din_config).to(DEVICE)
    
    trainer = Trainer(
        model=din_model,
        device=DEVICE,
        learning_rate=args.lr,
        weight_decay=1e-5
    )
    
    t1 = time.time()
    trainer.train(
        train_loader,
        valid_loader,
        epochs=args.epochs,
        early_stopping_patience=10
    )
    din_train_time = time.time() - t1
    
    # DIN è¯„ä¼°
    din_test_results = trainer.evaluate(test_loader)
    print(f"\nâœ… DIN è®­ç»ƒå®Œæˆ")
    print(f"   è®­ç»ƒæ—¶é—´: {din_train_time:.1f}s")
    print(f"   Test AUC: {din_test_results['auc']:.4f}")
    print(f"   Test LogLoss: {din_test_results['logloss']:.4f}")
    
    # ========================================
    # 4. è®­ç»ƒæ··åˆç²¾æ’æ¨¡å‹
    # ========================================
    print("\n" + "=" * 60)
    print("ğŸ”¥ Step 4: è®­ç»ƒæ··åˆç²¾æ’æ¨¡å‹ (DIN + LightGBM)")
    print("=" * 60)
    
    hybrid_ranker = HybridRanker(
        din_model,
        device=DEVICE,
        feature_processor=feature_processor,
        interaction_extractor=interaction_extractor
    )
    
    t2 = time.time()
    hybrid_ranker.fit(
        train_loader,
        valid_loader,
        num_boost_round=args.lgb_rounds,
        early_stopping_rounds=args.early_stop
    )
    lgb_train_time = time.time() - t2
    
    # æ··åˆæ¨¡å‹è¯„ä¼°
    hybrid_test_results = hybrid_ranker.evaluate(test_loader)
    
    print(f"\nâœ… æ··åˆç²¾æ’è®­ç»ƒå®Œæˆ")
    print(f"   LightGBMè®­ç»ƒæ—¶é—´: {lgb_train_time:.1f}s")
    print(f"   Test AUC: {hybrid_test_results['auc']:.4f}")
    print(f"   Test LogLoss: {hybrid_test_results['logloss']:.4f}")
    
    # ========================================
    # 5. Top-K è¯„ä¼°
    # ========================================
    print("\n" + "=" * 60)
    print("ğŸ“Š Step 5: Top-K æ¨èè¯„ä¼°")
    print("=" * 60)
    
    # å‡†å¤‡ Top-K è¯„ä¼°æ•°æ®
    eval_data = data_loader.prepare_topk_eval_data(num_neg=99)
    
    topk_metrics = hybrid_ranker.evaluate_topk(
        eval_data=eval_data,
        feature_processor=feature_processor,
        interaction_extractor=interaction_extractor,
        max_seq_length=args.seq_length,
        ks=(5, 10, 20),
        device=DEVICE
    )
    
    print(f"âœ… Top-K è¯„ä¼°å®Œæˆ")
    for k in [5, 10, 20]:
        print(f"   @{k}: HR={topk_metrics[f'HR@{k}']:.4f}, NDCG={topk_metrics[f'NDCG@{k}']:.4f}, MRR={topk_metrics[f'MRR@{k}']:.4f}")
    
    # ========================================
    # 6. å¯è§£é‡Šæ€§åˆ†æ
    # ========================================
    print("\n" + "=" * 60)
    print("ğŸ” Step 6: å¯è§£é‡Šæ€§åˆ†æ - ç‰¹å¾é‡è¦æ€§")
    print("=" * 60)
    
    # è·å–ç‰¹å¾é‡è¦æ€§ï¼ˆTop 20ï¼‰
    feature_importance = hybrid_ranker.get_feature_importance(20)
    feature_importance_dict = {name: float(imp) for name, imp in feature_importance}
    
    print("\nğŸ“ˆ ç‰¹å¾é‡è¦æ€§ Top 20:")
    print("-" * 50)
    
    # åˆ†ç±»å±•ç¤º
    din_emb_features = []
    explicit_features = []
    
    for i, (name, imp) in enumerate(feature_importance, 1):
        if name.startswith('din_emb_'):
            din_emb_features.append((name, imp))
        else:
            explicit_features.append((name, imp))
        print(f"  {i:2d}. {name:<25s}: {imp:>10.2f}")
    
    # ç»Ÿè®¡åˆ†æ
    total_importance = sum(imp for _, imp in feature_importance)
    din_importance = sum(imp for _, imp in din_emb_features)
    explicit_importance = sum(imp for _, imp in explicit_features)
    
    print("\nğŸ“Š ç‰¹å¾è´¡çŒ®åˆ†æ:")
    print(f"   DINåµŒå…¥ç‰¹å¾è´¡çŒ®: {din_importance/total_importance*100:.1f}%")
    print(f"   æ˜¾å¼ç‰¹å¾è´¡çŒ®: {explicit_importance/total_importance*100:.1f}%")
    
    if explicit_features:
        print(f"\nğŸ“ æœ€é‡è¦çš„æ˜¾å¼ç‰¹å¾:")
        for name, imp in explicit_features[:5]:
            print(f"   - {name}: {imp:.2f}")
    
    # ========================================
    # 7. æ¨¡å‹å¯¹æ¯”
    # ========================================
    print("\n" + "=" * 60)
    print("âš–ï¸ Step 7: DIN vs Hybrid å¯¹æ¯”")
    print("=" * 60)
    
    comparison = hybrid_ranker.compare_with_din()
    
    # ========================================
    # 8. ä¿å­˜ç»“æœ
    # ========================================
    print("\n" + "=" * 60)
    print("ğŸ’¾ Step 8: ä¿å­˜ç»“æœ")
    print("=" * 60)
    
    os.makedirs(args.output_dir, exist_ok=True)
    
    end_time = datetime.now()
    total_time = (end_time - start_time).total_seconds()
    
    # æ„å»ºå®Œæ•´ç»“æœ
    results = {
        'timestamp': datetime.now().strftime('%Y%m%d_%H%M%S'),
        'config': {
            'dataset': args.dataset,
            'seq_length': args.seq_length,
            'embedding_dim': args.embedding_dim,
            'batch_size': args.batch_size,
            'din_epochs': args.epochs,
            'lgb_rounds': args.lgb_rounds,
            'device': DEVICE,
            'gpu_name': torch.cuda.get_device_name(0) if DEVICE == 'cuda' else 'N/A'
        },
        'din_results': {
            'test_auc': din_test_results['auc'],
            'test_logloss': din_test_results['logloss'],
            'train_time_sec': din_train_time,
            'num_params': sum(p.numel() for p in din_model.parameters())
        },
        'hybrid_results': {
            'test_auc': hybrid_test_results['auc'],
            'test_logloss': hybrid_test_results['logloss'],
            'lgb_train_time_sec': lgb_train_time,
            'total_train_time_sec': din_train_time + lgb_train_time,
            'lgb_num_trees': hybrid_ranker.lgb_model.num_trees(),
            'lgb_best_iteration': hybrid_ranker.lgb_model.best_iteration
        },
        'topk_metrics': topk_metrics,
        'interpretability': {
            'feature_importance_top20': feature_importance_dict,
            'embedding_dim': hybrid_ranker.embedding_dim,
            'num_explicit_features': len(EXPLICIT_FEATURE_NAMES),
            'total_features': len(hybrid_ranker.feature_names),
            'din_emb_contribution_pct': din_importance / total_importance * 100,
            'explicit_contribution_pct': explicit_importance / total_importance * 100,
            'top_explicit_features': {name: float(imp) for name, imp in explicit_features[:10]}
        },
        'comparison': {
            'din_auc': comparison['din']['auc'],
            'hybrid_auc': comparison['hybrid']['auc'],
            'auc_improvement_pct': comparison['auc_improvement']
        },
        'total_time_minutes': total_time / 60
    }
    
    # ä¿å­˜ JSON
    json_file = os.path.join(args.output_dir, f'hybrid_analysis_{args.dataset}.json')
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {json_file}")
    
    # ========================================
    # 9. æ€»ç»“
    # ========================================
    print("\n" + "=" * 80)
    print("ğŸ‰ è®­ç»ƒå®Œæˆ!")
    print("=" * 80)
    print(f"\nğŸ“Š æ€§èƒ½æ€»ç»“:")
    print(f"   {'æ¨¡å‹':<15} {'AUC':<12} {'LogLoss':<12}")
    print(f"   {'-'*40}")
    print(f"   {'DIN':<15} {din_test_results['auc']:<12.4f} {din_test_results['logloss']:<12.4f}")
    print(f"   {'Hybrid':<15} {hybrid_test_results['auc']:<12.4f} {hybrid_test_results['logloss']:<12.4f}")
    print(f"   {'-'*40}")
    print(f"   AUCå˜åŒ–: {comparison['auc_improvement']:+.2f}%")
    
    print(f"\nâ±ï¸ æ—¶é—´ç»Ÿè®¡:")
    print(f"   DINè®­ç»ƒ: {din_train_time:.1f}s")
    print(f"   LightGBMè®­ç»ƒ: {lgb_train_time:.1f}s")
    print(f"   æ€»æ—¶é—´: {total_time/60:.1f}åˆ†é’Ÿ")
    
    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print(f"   {json_file}")
    
    return results


if __name__ == '__main__':
    print("\n" + "=" * 80)
    print("ğŸ¬ æ··åˆç²¾æ’æ¨¡å‹è®­ç»ƒè„šæœ¬å¯åŠ¨")
    print("=" * 80)
    
    try:
        results = main()
        print("\nâœ… è„šæœ¬æ‰§è¡ŒæˆåŠŸ!")
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
        sys.exit(0)
    except Exception as e:
        print("\n\nâŒ è„šæœ¬æ‰§è¡Œå¤±è´¥!")
        print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
